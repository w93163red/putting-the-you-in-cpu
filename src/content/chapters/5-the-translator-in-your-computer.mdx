---
chapter: 5
title: The Translator in Your Computer
shortname: Paging
slug: the-translator-in-your-computer
updatedAt: 2023-08-15T18:49:01.686Z
---

import CodeBlock from '../../components/CodeBlock.astro'

直到现在,我每次谈到读写内存时都有点模糊。例如,ELF 文件指定了将数据加载到的特定内存地址,那为什么不同进程试图使用冲突的内存时不会出现问题?为什么每个进程似乎都有不同的内存环境?

此外,我们究竟是如何到达这里的?我们理解 `execve` 是一个将当前进程替换为新程序的系统调用,但这并不能解释如何启动多个进程。它绝对无法解释第一个程序是如何运行的 - 是哪只鸡(进程)下(生成)了所有其他的蛋(其他进程)?

我们正接近旅程的终点。在回答了这两个问题之后,我们将对你的计算机如何从启动到运行你现在正在使用的软件有一个基本完整的理解。

## 内存是假的

所以...关于内存。事实证明,当 CPU 从内存地址读取或写入时,它实际上并不是指*物理*内存(RAM)中的那个位置。相反,它指向的是*虚拟*内存空间中的一个位置。
 
CPU 与一个叫做[*内存管理单元*](https://en.wikipedia.org/wiki/Memory_management_unit)(MMU)的芯片通信。MMU 的工作就像一个带字典的翻译员,将虚拟内存中的位置翻译成 RAM 中的位置。当 CPU 接收到从内存地址 `0xfffaf54834067fe2` 读取的指令时,它会要求 MMU 翻译该地址。MMU 在字典中查找,发现匹配的物理地址是 `0x53a4b64a90179fe2`,并将该数字发送回 CPU。然后 CPU 就可以从 RAM 中的那个地址读取了。

<img src='/images/virtual-memory-mmu-example.png' loading='eager' style='max-width: 640px; margin: 0 auto;' alt='A drawing of a smiling CPU and an MMU having a conversation. The MMU is a tall chip, wearing library glasses, and holding a large book labeled "Dictionary: Pointers 0x0000 to 0xffff." The CPU asks the MMU to translate a long memory address. The MMU thinks for a second, and responds with a different pointer.' width='1207' height='454' />

当计算机首次启动时,内存访问直接去到物理 RAM。在启动后立即,操作系统创建翻译字典并告诉 CPU 开始使用 MMU。

这个字典实际上被称为*页表*,这个翻译每次内存访问的系统被称为*分页*。页表中的条目被称为*页*,每一页表示虚拟内存中某个块如何映射到 RAM。这些块总是固定大小的,每种处理器架构都有不同的页面大小。x86-64 的默认页面大小为 4 KiB,这意味着每个页面指定了一个 4,096 字节长的内存块的映射。

换句话说,使用 4 KiB 页面时,地址的底部 12 位在 MMU 翻译前后总是相同的 - 12,因为这是索引翻译后得到的 4,096 字节页面所需的位数。

x86-64 还允许操作系统启用更大的 2 MiB 或 4 GiB 页面,这可以提高地址翻译速度,但会增加内存碎片和浪费。页面大小越大,MMU 翻译的地址部分就越小。

<img src='/images/4kib-paging-address-breakdown.png' loading='lazy' style='max-width: 400px; margin: 0 auto;' alt='A breakdown of a memory address with 4 KiB paging. The lowest 12 bits index the page, and the rest of the bits are translated by the MMU and become the page&apos;s start address.' width='760' height='310' />

页表本身就存在于 RAM 中。虽然它可以包含数百万个条目,但每个条目的大小仅为几个字节,所以页表不会占用太多空间。

要在启动时启用分页,内核首先在 RAM 中构建页表。然后,它将页表开始的物理地址存储在一个称为页表基址寄存器(PTBR)的寄存器中。最后,内核启用分页,用 MMU 翻译所有内存访问。在 x86-64 上,控制寄存器 3(CR3)的前 20 位作为 PTBR。CR0 的第 31 位,指定为 PG(分页),设置为 1 以启用分页。

分页系统的魔力在于可以在计算机运行时编辑页表。这就是每个进程如何拥有自己的独立内存空间 - 当操作系统从一个进程切换到另一个进程时,一个重要的任务是将虚拟内存空间重新映射到物理内存中的不同区域。假设你有两个进程:进程 A 可以在 `0x0000000000400000` 处访问其代码和数据(可能是从 ELF 文件加载的!),进程 B 可以从完全相同的地址访问其代码和数据。这两个进程甚至可以是同一程序的实例,因为它们实际上并没有争夺那个地址范围!进程 A 的数据在物理内存中离进程 B 很远,当切换到该进程时,内核将其映射到 `0x0000000000400000`。

<img src='/images/process-virtual-memory-mapping.png' loading='lazy' alt='A diagram showing two different processes asking a cheesy clip art image of an anthropomorphic desktop computer to translate the same memory address. The anthropomorphic computer responds to each process with a different section from within the continuous strip of physical memory.' width='2101' height='1010' />

> **题外话:诅咒般的 ELF 事实**
>
> 在某些情况下,`binfmt_elf` 必须将内存的第一页映射为零。一些为 UNIX System V Release 4.0(SVr4)编写的程序,这是 1988 年第一个支持 ELF 的操作系统,依赖于空指针的可读性。而且不知何故,一些程序仍然依赖于那种行为。
>
> 看起来实现这一点的 Linux 内核开发者[有点不满](https://github.com/torvalds/linux/blob/22b8cc3e78f5448b4c5df00303817a9137cd663f/fs/binfmt_elf.c#L1322-L1329):
>
> *"为什么这样,你问???  好吧,SVr4 将第 0 页映射为只读,一些应用程序'依赖'于这种行为。由于我们没有能力重新编译这些,我们模拟 SVr4 的行为。叹气。"*
>
> 叹气。

## 使用分页实现安全

内存分页实现的进程隔离改善了代码的人体工程学(进程不需要意识到其他进程就可以使用内存),但它也创造了一个安全层次:进程无法访问其他进程的内存。这部分回答了本文开头提出的一个原始问题:

> 如果程序直接在 CPU 上运行,而 CPU 可以直接访问 RAM,为什么代码不能访问其他进程的内存,或者天啊,内核的内存?

*还记得吗?感觉已经过去很久了...*

那内核内存呢?首先:内核显然需要存储大量自己的数据来跟踪所有正在运行的进程,甚至是页表本身。每次触发硬件中断、软件中断或系统调用,CPU 进入内核模式时,内核代码都需要以某种方式访问那个内存。

Linux 的解决方案是始终将虚拟内存空间的上半部分分配给内核,所以 Linux 被称为[*高半内核*](https://wiki.osdev.org/Higher_Half_Kernel)。Windows 采用了[类似的](https://learn.microsoft.com/en-us/windows-hardware/drivers/kernel/overview-of-windows-memory-space)技术,而 macOS 则...[稍微](https://www.researchgate.net/figure/Overview-of-the-Mac-OS-X-virtual-memory-system-which-resides-inside-the-Mach-portion-of_fig1_264086271) [更](https://developer.apple.com/library/archive/documentation/Performance/Conceptual/ManagingMemory/Articles/AboutMemory.html) [复杂](https://developer.apple.com/library/archive/documentation/Darwin/Conceptual/KernelProgramming/vm/vm.html),阅读它让我的大脑从耳朵里流了出来。\~(++)\~

<img src='/images/higher-half-kernel-memory-map.png' loading='lazy' alt='A diagram showing virtual memory space as a strip. The left half is labeled user space: memory for the executing program. The right half is labeled kernel space: fixed area for everything kernel-related. The middle point splitting the two segments is labeled with the memory address 0x8000000000000000.' width='2161' height='230' />

如果用户空间进程可以读写内核内存,那将是安全性的灾难,所以分页启用了第二层安全:每个页面必须指定权限标志。一个标志决定该区域是可写的还是只读的。另一个标志告诉 CPU 只有内核模式才允许访问该区域的内存。后一个标志用于保护整个高半内核空间 - 整个内核内存空间实际上在用户空间程序的虚拟内存映射中可用,它们只是没有权限访问它。

<img src='/images/page-table-entry-permissions.png' loading='lazy' style='max-width: 260px;' alt='A table of page table entry permissions. Present: true. Read/write: read only. User/kernel: all modes. Dirty: false. Accessed: true. Etcetera.' width='650' height='639' />

页表本身实际上包含在内核内存空间中!当定时器芯片触发进程切换的硬件中断时,CPU 将特权级别切换到内核模式并跳转到 Linux 内核代码。处于内核模式(Intel ring 0)允许 CPU 访问受内核保护的内存区域。然后内核可以写入页表(位于内存上半部分的某个地方)以重新映射新进程的虚拟内存下半部分。当内核切换到新进程并且 CPU 进入用户模式时,它不能再访问任何内核内存。

几乎每次内存访问都要经过 MMU。中断描述符表处理程序指针?那些也寻址内核的虚拟内存空间。

## 分层分页和其他优化

64 位系统的内存地址长 64 位,这意味着 64 位虚拟内存空间的大小高达 16 [艾字节](https://en.wiktionary.org/wiki/exbibyte)。这是非常大的,远远大于现在或不久的将来存在的任何计算机。据我所知,任何计算机中最大的 RAM 是在[蓝水超级计算机](https://en.wikipedia.org/wiki/Blue_Waters)中,有超过 1.5 拍字节的 RAM。这仍然不到 16 EiB 的 0.01%。

如果虚拟内存空间的每个 4 KiB 部分都需要页表中的一个条目,你将需要 4,503,599,627,370,496 个页表条目。如果页表条目长 8 字节,你将需要 32 皮字节的 RAM 仅用于存储页表。你可能注意到这仍然大于世界纪录的计算机 RAM 最大值。

> **题外话:为什么用这些奇怪的单位?**
> 
> 我知道这很不常见而且真的很难看,但我认为清楚地区分二进制字节大小单位(2 的幂)和公制单位(10 的幂)很重要。千字节,kB,是一个 SI 单位,表示 1,000 字节。kibibyte,KiB,是 IEC 推荐的单位,表示 1,024 字节。就 CPU 和内存地址而言,字节计数通常是 2 的幂,因为计算机是二进制系统。使用 KB(或更糟的 kB)来表示 1,024 会更加模糊。

由于不可能(或至少非常不切实际)对整个可能的虚拟内存空间有连续的页表条目,CPU 架构实现了*分层分页*。在分层分页系统中,有多个级别的页表,粒度越来越小。顶级条目覆盖大块内存,并指向更小块的页表,创建一个树结构。4 KiB 或任何页面大小的单个块的条目是树的叶子。

x86-64 历史上使用 4 级分层分页。在这个系统中,每个页表条目都是通过将包含表的开始偏移地址的一部分来找到的。这部分从最高有效位开始,作为前缀,使得条目覆盖所有以这些位开始的地址。该条目指向下一级表的开始,该表包含该内存块的子树,再次用下一组位进行索引。

x86-64 的 4 级分页设计者还选择忽略所有虚拟指针的前 16 位以节省页表空间。48 位可以得到 128 TiB 的虚拟地址空间,这被认为足够大了。(完整的 64 位会得到 16 EiB,这有点太多了。)

由于跳过了前 16 位,所以用于索引页表第一级的"最高有效位"实际上从第 47 位而不是第 63 位开始。这也意味着本章前面的高半内核图在技术上是不准确的;内核空间的起始地址应该被描绘为小于 64 位的地址空间的中点。

<img src='/images/multilevel-paging-explainer.png' loading='lazy' class='big' alt='A large, detailed, and full-color diagram of 4-level paging on x86-64. It depicts the four levels of page tables, highlighting the bits that serve as a "prefix" at each level. It also shows the tables being indexed by those prefix bits by adding the value of the bits to the table&apos;s base address. The entries in each table point to the start of the next table, except for the final level 1 which points to the start of a 4 KiB block in RAM. The MMU adds the lowest 12 bits to that address to get the final physical address. There is one level 4 table, n-squared level 3 tables, and so on.' width='2981' height='1118' />

分层分页解决了空间问题,因为在树的任何级别,指向下一个条目的指针都可以为空(`0x0`)。这允许省略页表的整个子树,意味着虚拟内存空间的未映射区域不会占用 RAM 中的任何空间。未映射内存地址的查找可以快速失败,因为 CPU 一旦在树的更高层看到空条目就可以报错。页表条目还有一个存在标志,即使地址看起来有效,也可以用它来标记它们为不可用。

分层分页的另一个好处是能够高效地切换虚拟内存空间的大块。对于一个进程,大片虚拟内存可能映射到物理内存的一个区域,而对于另一个进程,则映射到不同的区域。内核可以将两种映射都存储在内存中,并在切换进程时简单地更新树顶层的指针。如果整个内存空间映射存储为条目的平面数组,内核将不得不更新大量条目,这将很慢,而且仍然需要独立地跟踪每个进程的内存映射。

我说 x86-64 "历史上"使用 4 级分页是因为最近的处理器实现了[5 级分页](https://en.wikipedia.org/wiki/Intel_5-level_paging)。5 级分页增加了另一级间接寻址,以及 9 个更多的寻址位,将地址空间扩展到 128 PiB,使用 57 位地址。5 级分页得到了包括 Linux [自 2017 年以来](https://lwn.net/Articles/717293/)以及最近的 Windows 10 和 11 服务器版本在内的操作系统的支持。

> **题外话:物理地址空间限制**
> 
> 正如操作系统不使用全部 64 位作为虚拟地址,处理器也不使用整个 64 位物理地址。当 4 级分页是标准时,x86-64 CPU 不使用超过 46 位,这意味着物理地址空间仅限于 64 TiB。有了 5 级分页,支持扩展到了 52 位,支持 4 PiB 的物理地址空间。
>
> 在操作系统级别,虚拟地址空间大于物理地址空间是有利的。正如 Linus Torvalds [所说](https://www.realworldtech.com/forum/?threadid=76912&curpostid=76973),"它需要更大,至少要大两倍,而这实际上已经很勉强了,你最好有十倍或更多。任何不明白这一点的人都是个白痴。讨论结束。"

## 交换和按需分页

内存访问可能因为几个原因而失败:地址可能超出范围,可能没有被页表映射,或者可能有一个被标记为不存在的条目。在这些情况下,MMU 将触发一个称为*页错误*的硬件中断,让内核处理这个问题。

在某些情况下,读取确实是无效或被禁止的。在这些情况下,内核可能会以[段错误](https://en.wikipedia.org/wiki/Segmentation_fault)错误终止程序。

<CodeBlock name='Shell session'>
```
$ ./program
Segmentation fault (core dumped)
$
```
</CodeBlock>

> **题外话:段错误的本体论**
> 
> "段错误"在不同的上下文中意味着不同的东西。当内存在没有权限的情况下被读取时,MMU 触发一个称为"段错误"的硬件中断,但"段错误"也是操作系统可以发送给正在运行的程序的信号的名称,用于因任何非法内存访问而终止它们。

在其他情况下,内存访问可以*有意*失败,允许操作系统填充内存,然后*将控制权交还给 CPU 重试*。例如,操作系统可以将磁盘上的文件映射到虚拟内存,而不实际将其加载到 RAM 中,然后在请求地址并发生页错误时将其加载到物理内存中。这被称为*按需分页*。

<img src='/images/demand-paging-with-page-faults-comic.png' loading='lazy' class='big' alt='A three-panel comic style diagram about how demand paging is implemented with hardware interrupts. Panel 1: the CPU having a conversation with the MMU. The CPU says "read 0xfff," the MMU looks confused, and then the MMU sends a lightning to the CPU labeled "page fault!" Panel 2 is labeled "page fault handler" and has a zig-zag outline. It depicts the CPU loading some data into RAM, and then returning from the interrupt. Finally, panel 3 is back to the CPU and MMU conversing. The MMU thinks to itself, "Oh hey, the page is present now." It replies to the CPU&apos;s original request: "Here&apos;s your memory!" The CPU says thank you.' width='3001' height='703' style='--max-width: 1000px;' />

首先,这允许像 [mmap](https://man7.org/linux/man-pages/man2/mmap.2.html) 这样的系统调用存在,它可以懒惰地将整个文件从磁盘映射到虚拟内存。如果你熟悉 LLaMa.cpp,一个泄露的 Facebook 语言模型的运行时,Justine Tunney 最近通过[使所有加载逻辑使用 mmap](https://justine.lol/mmap/) 显著优化了它。(如果你以前没听说过她,[看看她的东西](https://justine.lol/)!Cosmopolitan Libc 和 APE 真的很酷,如果你一直在享受这篇文章的话,可能会觉得有趣。)

> *显然关于 Justine 参与这个变更有[很多](https://rentry.org/Jarted) [戏](https://news.ycombinator.com/item?id=35413289) [剧](https://news.ycombinator.com/item?id=35458004)。我只是指出这一点,这样我就不会被随机的互联网用户大喊大叫。我必须承认我没有读过大部分戏剧,我说的关于 Justine 的东西很酷仍然是非常正确的。*

当你执行一个程序及其库时,内核实际上并不将任何东西加载到内存中。它只创建文件的 mmap - 当 CPU 试图执行代码时,页面立即发生错误,内核用一个真正的内存块替换页面。

按需分页还启用了你可能在"交换"或"分页"名下看到的技术。操作系统可以通过将内存页写入磁盘然后从物理内存中移除它们来释放物理内存,但将它们保留在虚拟内存中,同时将存在标志设置为 0。如果读取该虚拟内存,操作系统可以从磁盘将内存恢复到 RAM,并将存在标志设回 1。操作系统可能必须交换出不同的 RAM 部分,为正在从磁盘加载的内存腾出空间。磁盘读写很慢,所以操作系统尝试通过[高效的页面替换算法](https://en.wikipedia.org/wiki/Page_replacement_algorithm)使交换尽可能少发生。

一个有趣的技巧是使用页表物理内存指针来存储文件在物理存储中的位置。由于 MMU 一看到负的存在标志就会引发页错误,所以它们是无效的内存地址并不重要。这在所有情况下都不实用,但想想还是很有趣的。